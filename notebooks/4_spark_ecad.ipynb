{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6345672-3fb9-45ec-8f2e-eb141f32467d",
   "metadata": {},
   "source": [
    "# Analyse ECAD Daten mit Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7ae37-9fd0-4aad-b33a-666a4c862bc4",
   "metadata": {},
   "source": [
    "## Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c2d52-b3aa-429f-864b-cf33a01d0da6",
   "metadata": {},
   "source": [
    "Auf der Seite European Climate Assessment & Dataset https://www.ecad.eu/ findet man tägliche Beobachtungen an meteorologischen Stationen in ganz Europa und im Mittelmeerraum aus der Vergangehiet bis fast in die aktuelle Gegenwart. Insgesamt handelt es sich um 81366 Beobachtungsreihen für 13 Elemente an 22359 meteorologischen Stationen. Es sind sowohl gemischte als auch nicht gemischte ECA-Reihen verfügbar. Bei gemischten Reihen handelt es sich um Reihen, die durch Auffüllen von benachbarten Stationen nahezu vollständig sind. Die Reihen werden einer Qualitätskontrolle unterzogen\n",
    "\n",
    "Für unsere Analyse haben wir uns für Daten von 4 Wetterstationen aus Österreich interessiert:<Br>\n",
    "Krems: Daten von 1936 bis 2021. <Br>\n",
    "Poysdorf: Daten von 1965 bis 2021. <Br>\n",
    "Neusiedl am See: Daten von 1936 bis 2021<Br>\n",
    "Güssing: Daten von 1947 bis 2021.\n",
    "\n",
    "Für diese Standorte haben wir die jeweiligen Dateien für mittlere Temperatur/Tag und Regenmenge/Tag heruntergeladen. <Br>\n",
    "Dateiformat: .txt – wobei die Daten mit dem Wert -9999 fehlende Werte darstellen <Br>\n",
    "STAID: gibt die Wetterstation an <Br>\n",
    "SOUID: gibt den Standort der Station an zB Krems <Br>\n",
    "Datum: wird im Format YYYYMMDD ausgegeben \n",
    "\n",
    "ECAD Temperatur <Br>\n",
    "TG: Durchschnittstemperatur wird in 0.1 °C angegeben<Br>\n",
    "Q_TG: gibt die Qualität der Temperaturdaten an (0= valid, 1=suspect, 9= missing) \n",
    "\n",
    "ECAD Regen<Br>\n",
    "RR: Durchschnittsniederschlag wird in 0.1 mm angegeben<Br>\n",
    "Q_RR: gibt die Qualität der Niederschlagsdaten an (0=valid, 1=suspect, 9=missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59224018-5936-40c2-af40-6f6bb90e0d2f",
   "metadata": {},
   "source": [
    "## Regendaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33514181-585e-400c-960b-eca6bec7a23c",
   "metadata": {},
   "source": [
    "### Datenmanagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc734ef-8df4-4c08-9af1-8a964acdce1f",
   "metadata": {},
   "source": [
    "Zunächst werden die notwenigen Libraries geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b0b46a-5618-47d7-8a7e-34fb0e9f1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "#edac_raw = '../data/ecad/RR_SOUID234717.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5173206-248e-4d1f-ae96-e8d227a5b398",
   "metadata": {},
   "source": [
    "Da es nicht möglich ist, mit SparkSession Headerzeilen zu skippen, lesen wir die Daten zuerst als Panda ein, entfernen die unnötigen Zeilen und konvertieren dann in ein Spark-Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef9381-25a7-4163-860b-3201a849c14a",
   "metadata": {},
   "source": [
    "Im ersten Schritt wurden die Regendaten/Tag der Stationen Krems, Poysdorf-Ost, Neusiedl/See sowie Güssing heruntergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "838a116f-5dae-467e-a195-d87e54028b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ecad/RR_SOUID234717.txt',\n",
       " '../data/ecad/RR_SOUID234938.txt',\n",
       " '../data/ecad/RR_SOUID235003.txt',\n",
       " '../data/ecad/RR_SOUID236251.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/ecad/'\n",
    "all_files = glob.glob(path + 'RR_*.txt')\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34930e2-5593-4ef5-ae83-cc244381d3dd",
   "metadata": {},
   "source": [
    "Speichern aller Daten in einem Panda-Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ee8fd17-da61-491c-9e0c-95a5e2c23d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAID</th>\n",
       "      <th>SOUID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>RR</th>\n",
       "      <th>Q_RR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24702</td>\n",
       "      <td>234717</td>\n",
       "      <td>19360101</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24702</td>\n",
       "      <td>234717</td>\n",
       "      <td>19360102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24702</td>\n",
       "      <td>234717</td>\n",
       "      <td>19360103</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24702</td>\n",
       "      <td>234717</td>\n",
       "      <td>19360104</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24702</td>\n",
       "      <td>234717</td>\n",
       "      <td>19360105</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110843</th>\n",
       "      <td>24820</td>\n",
       "      <td>236251</td>\n",
       "      <td>20220426</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110844</th>\n",
       "      <td>24820</td>\n",
       "      <td>236251</td>\n",
       "      <td>20220427</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110845</th>\n",
       "      <td>24820</td>\n",
       "      <td>236251</td>\n",
       "      <td>20220428</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110846</th>\n",
       "      <td>24820</td>\n",
       "      <td>236251</td>\n",
       "      <td>20220429</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110847</th>\n",
       "      <td>24820</td>\n",
       "      <td>236251</td>\n",
       "      <td>20220430</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110848 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STAID      SOUID      DATE     RR   Q_RR\n",
       "0        24702     234717  19360101  -9999      9\n",
       "1        24702     234717  19360102      1      0\n",
       "2        24702     234717  19360103      3      0\n",
       "3        24702     234717  19360104     44      0\n",
       "4        24702     234717  19360105     11      0\n",
       "...        ...        ...       ...    ...    ...\n",
       "110843   24820     236251  20220426  -9999      9\n",
       "110844   24820     236251  20220427  -9999      9\n",
       "110845   24820     236251  20220428  -9999      9\n",
       "110846   24820     236251  20220429  -9999      9\n",
       "110847   24820     236251  20220430  -9999      9\n",
       "\n",
       "[110848 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename\n",
    "                     , index_col=None\n",
    "                     , header=0\n",
    "                     , sep=\",\"\n",
    "                   , skiprows=18)\n",
    "    li.append(df)\n",
    "\n",
    "data = pd.concat(li, axis=0, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ac9d8d-78fa-4e1e-8214-d582cd391d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edac ######### Krems Regen\n",
    "#data = pd.read_csv(edac_raw\n",
    "#                   , sep=\",\"\n",
    "#                   , skiprows=18\n",
    "#                   , header=0)\n",
    "#data.head(5)\n",
    "#len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edf404-2e93-438b-ae1a-82fc273105a8",
   "metadata": {},
   "source": [
    "Einlesen der Panda-Dataframes mit Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8193db0-f93c-4908-8024-5b06728435e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |--  STAID: long (nullable = true)\n",
      " |--     SOUID: long (nullable = true)\n",
      " |--     DATE: long (nullable = true)\n",
      " |--    RR: long (nullable = true)\n",
      " |--  Q_RR: long (nullable = true)\n",
      "\n",
      "+------+---------+--------+-----+-----+\n",
      "| STAID|    SOUID|    DATE|   RR| Q_RR|\n",
      "+------+---------+--------+-----+-----+\n",
      "| 24702|   234717|19360101|-9999|    9|\n",
      "| 24702|   234717|19360102|    1|    0|\n",
      "| 24702|   234717|19360103|    3|    0|\n",
      "| 24702|   234717|19360104|   44|    0|\n",
      "| 24702|   234717|19360105|   11|    0|\n",
      "| 24702|   234717|19360106|    0|    0|\n",
      "| 24702|   234717|19360107|    0|    0|\n",
      "| 24702|   234717|19360108|    0|    0|\n",
      "| 24702|   234717|19360109|    1|    0|\n",
      "| 24702|   234717|19360110|   53|    0|\n",
      "| 24702|   234717|19360111|   51|    0|\n",
      "| 24702|   234717|19360112|   13|    0|\n",
      "| 24702|   234717|19360113|    0|    0|\n",
      "| 24702|   234717|19360114|    0|    0|\n",
      "| 24702|   234717|19360115|    0|    0|\n",
      "| 24702|   234717|19360116|    0|    0|\n",
      "| 24702|   234717|19360117|    0|    0|\n",
      "| 24702|   234717|19360118|    0|    0|\n",
      "| 24702|   234717|19360119|    0|    0|\n",
      "| 24702|   234717|19360120|    0|    0|\n",
      "+------+---------+--------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Read Data\") \\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF=spark.createDataFrame(data) \n",
    "sparkDF.printSchema()\n",
    "sparkDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea1c45-2110-41cd-a11a-df60ccd6b7f2",
   "metadata": {},
   "source": [
    "### Bereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b50ff8-cd8a-48f1-b18b-a6d638a2546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' STAID', '    SOUID', '    DATE', '   RR', ' Q_RR']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF.schema.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeca985-6f87-4e81-bef0-f6bd7056c0ff",
   "metadata": {},
   "source": [
    "Bei Ansicht des Schemas sieht man, dass die Spalten mit Leerzeichen beginnen, deshalb speichern wir diese um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a095a63-e516-44fa-92d5-75c0922e5065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAID', 'SOUID', 'DATE', 'RR', 'Q_RR']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=['STAID', 'SOUID', 'DATE', 'RR', 'Q_RR']\n",
    "sparkDF = sparkDF.toDF(*column_names)\n",
    "sparkDF.schema.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadfa0a-1b02-4ce2-ad31-68be45896e4b",
   "metadata": {},
   "source": [
    "Ausgabe der Anzahl der Datensätze / Station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36710e44-15a7-4aff-8bab-bcfab7ab08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| SOUID|count|\n",
      "+------+-----+\n",
      "|234717|31532|\n",
      "|234938|31532|\n",
      "|235003|20635|\n",
      "|236251|27149|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.groupby('SOUID').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9312ff-3c47-4db0-8857-ae355ad15ba0",
   "metadata": {},
   "source": [
    "Da in den Metadaten die Info zu finden war, dass Datensätze in der Spalte \"Q_RR\" mit den Werten 1 oder 9 ungültige Daten enthalten, entfernen wir diese Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58015a5c-cd16-43e0-aed8-25a98daa5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDF = sparkDF.filter(col(\"Q_RR\") == '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53835e5-080a-4051-9234-bfdaebd34e69",
   "metadata": {},
   "source": [
    "Man sieht nun, dass einige Datensätze entfernt wurden, vor allem bei der Station 236251 (Güssing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e433e13f-67b9-435d-b292-5ca42426712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| SOUID|count|\n",
      "+------+-----+\n",
      "|234717|31411|\n",
      "|234938|30334|\n",
      "|235003|20515|\n",
      "|236251|17655|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.groupby('SOUID').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67557bb8-bf2b-47ca-a1e5-63c9910cf50e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STAID: long (nullable = true)\n",
      " |-- SOUID: long (nullable = true)\n",
      " |-- DATE: long (nullable = true)\n",
      " |-- RR: long (nullable = true)\n",
      " |-- Q_RR: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b3a7c-e7dc-4466-b201-01fdf1f17fd8",
   "metadata": {},
   "source": [
    "Nun werden noch die unnötigen Spalten entfernt: es stehen nun nur noch die interessierenden Werte Station, Datum und Regenmenge zur Verfügung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf2140c-0baf-46b2-ba94-ee6032f58042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+\n",
      "| SOUID|    DATE| RR|\n",
      "+------+--------+---+\n",
      "|234717|19360102|  1|\n",
      "|234717|19360103|  3|\n",
      "|234717|19360104| 44|\n",
      "|234717|19360105| 11|\n",
      "|234717|19360106|  0|\n",
      "|234717|19360107|  0|\n",
      "|234717|19360108|  0|\n",
      "|234717|19360109|  1|\n",
      "|234717|19360110| 53|\n",
      "|234717|19360111| 51|\n",
      "|234717|19360112| 13|\n",
      "|234717|19360113|  0|\n",
      "|234717|19360114|  0|\n",
      "|234717|19360115|  0|\n",
      "|234717|19360116|  0|\n",
      "|234717|19360117|  0|\n",
      "|234717|19360118|  0|\n",
      "|234717|19360119|  0|\n",
      "|234717|19360120|  0|\n",
      "|234717|19360121|  0|\n",
      "+------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF = sparkDF.drop(\"STAID\", \"Q_RR\")\n",
    "sparkDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d11ec80-b0e8-4376-8082-c1a29648566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SOUID: long (nullable = true)\n",
      " |-- DATE: long (nullable = true)\n",
      " |-- RR: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e76e89-2c16-44cc-9f57-94553743d143",
   "metadata": {},
   "source": [
    "Erneut speichern wir das File für die Regendaten lokal im hdf5-Format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46020299-e47c-464b-9465-4516093303a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = sparkDF.toPandas()\n",
    "rr.to_hdf('../data/ecad/RR.h5', key='all', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832268b4-e2f9-4fd3-aeea-92fb32ef03c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Temperaturdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1260104-8bfc-42fc-a9c3-dc3a30ec2341",
   "metadata": {},
   "source": [
    "### Datenmanagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e68e3-6836-4475-b8b5-36a97b12b4c2",
   "metadata": {},
   "source": [
    "Im ersten Schritt wurden die mittleren Temperaturdaten/Tage der Stationen Krems, Poysdorf-Ost, Neusiedl/See sowie Güssing heruntergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059cb095-352d-489c-a3a6-bcb302ee5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ecad/TG_SOUID234722.txt',\n",
       " '../data/ecad/TG_SOUID234943.txt',\n",
       " '../data/ecad/TG_SOUID235008.txt',\n",
       " '../data/ecad/TG_SOUID236256.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/ecad/'\n",
    "all_files = glob.glob(path + 'TG_*.txt')\n",
    "all_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dbc01-3c06-4a66-bc09-dc734fba5b15",
   "metadata": {},
   "source": [
    "Speichern aller Daten in einem Panda-Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d80cdd4-044d-4863-93c6-a6bf81ef9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAID</th>\n",
       "      <th>SOUID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TG</th>\n",
       "      <th>Q_TG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24702</td>\n",
       "      <td>234722</td>\n",
       "      <td>19360101</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24702</td>\n",
       "      <td>234722</td>\n",
       "      <td>19360102</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24702</td>\n",
       "      <td>234722</td>\n",
       "      <td>19360103</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24702</td>\n",
       "      <td>234722</td>\n",
       "      <td>19360104</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24702</td>\n",
       "      <td>234722</td>\n",
       "      <td>19360105</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110843</th>\n",
       "      <td>24820</td>\n",
       "      <td>236256</td>\n",
       "      <td>20220426</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110844</th>\n",
       "      <td>24820</td>\n",
       "      <td>236256</td>\n",
       "      <td>20220427</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110845</th>\n",
       "      <td>24820</td>\n",
       "      <td>236256</td>\n",
       "      <td>20220428</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110846</th>\n",
       "      <td>24820</td>\n",
       "      <td>236256</td>\n",
       "      <td>20220429</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110847</th>\n",
       "      <td>24820</td>\n",
       "      <td>236256</td>\n",
       "      <td>20220430</td>\n",
       "      <td>-9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110848 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STAID      SOUID      DATE     TG   Q_TG\n",
       "0        24702     234722  19360101     38      0\n",
       "1        24702     234722  19360102     33      0\n",
       "2        24702     234722  19360103     34      0\n",
       "3        24702     234722  19360104     51      0\n",
       "4        24702     234722  19360105     36      0\n",
       "...        ...        ...       ...    ...    ...\n",
       "110843   24820     236256  20220426  -9999      9\n",
       "110844   24820     236256  20220427  -9999      9\n",
       "110845   24820     236256  20220428  -9999      9\n",
       "110846   24820     236256  20220429  -9999      9\n",
       "110847   24820     236256  20220430  -9999      9\n",
       "\n",
       "[110848 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename\n",
    "                     , index_col=None\n",
    "                     , header=0\n",
    "                     , sep=\",\"\n",
    "                   , skiprows=18)\n",
    "    li.append(df)\n",
    "\n",
    "data = pd.concat(li, axis=0, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afdbb0-5abe-4f36-9167-1f51a9bd7cea",
   "metadata": {},
   "source": [
    "Einlesen der Panda-Dataframes mit Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e595acd0-ddbc-46a1-a469-b12093db8250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |--  STAID: long (nullable = true)\n",
      " |--     SOUID: long (nullable = true)\n",
      " |--     DATE: long (nullable = true)\n",
      " |--    TG: long (nullable = true)\n",
      " |--  Q_TG: long (nullable = true)\n",
      "\n",
      "+------+---------+--------+-----+-----+\n",
      "| STAID|    SOUID|    DATE|   TG| Q_TG|\n",
      "+------+---------+--------+-----+-----+\n",
      "| 24702|   234722|19360101|   38|    0|\n",
      "| 24702|   234722|19360102|   33|    0|\n",
      "| 24702|   234722|19360103|   34|    0|\n",
      "| 24702|   234722|19360104|   51|    0|\n",
      "| 24702|   234722|19360105|   36|    0|\n",
      "| 24702|   234722|19360106|    9|    0|\n",
      "| 24702|   234722|19360107|   -3|    0|\n",
      "| 24702|   234722|19360108|   30|    0|\n",
      "| 24702|   234722|19360109|    2|    0|\n",
      "| 24702|   234722|19360110|   56|    0|\n",
      "| 24702|   234722|19360111|  102|    0|\n",
      "| 24702|   234722|19360112|   56|    0|\n",
      "| 24702|   234722|19360113|   17|    0|\n",
      "| 24702|   234722|19360114|   17|    0|\n",
      "| 24702|   234722|19360115|    2|    0|\n",
      "| 24702|   234722|19360116|  -15|    0|\n",
      "| 24702|   234722|19360117|   -4|    0|\n",
      "| 24702|   234722|19360118|   14|    0|\n",
      "| 24702|   234722|19360119|  -14|    0|\n",
      "| 24702|   234722|19360120|   20|    0|\n",
      "+------+---------+--------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Read Data TG\") \\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF=spark.createDataFrame(data)\n",
    "sparkDF.printSchema()\n",
    "sparkDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d463c2-2205-427b-819d-bf4ad95f76d9",
   "metadata": {},
   "source": [
    "### Bereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2d84aa6-ad2a-40ba-8adc-3df1bff4239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' STAID', '    SOUID', '    DATE', '   TG', ' Q_TG']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDF.schema.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b54e2d-7533-489a-a137-522052f8263d",
   "metadata": {},
   "source": [
    "Bei Ansicht des Schemas sieht man, dass die Spalten mit Leerzeichen beginnen, deshalb speichern wir diese um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdd4902f-5269-40fe-a87b-e018f88a008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STAID', 'SOUID', 'DATE', 'TG', 'Q_TG']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=['STAID', 'SOUID', 'DATE', 'TG', 'Q_TG']\n",
    "sparkDF = sparkDF.toDF(*column_names)\n",
    "sparkDF.schema.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62e783-7c60-4def-a249-f15e6f581073",
   "metadata": {},
   "source": [
    "Ausgabe der Anzahl der Datensätze / Station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7d55018-5191-4d62-88f4-12751b2c1344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| SOUID|count|\n",
      "+------+-----+\n",
      "|234722|31532|\n",
      "|234943|31532|\n",
      "|235008|20635|\n",
      "|236256|27149|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.groupby('SOUID').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c7ebd-e264-4638-a2fe-38d7faac6585",
   "metadata": {},
   "source": [
    "Da in den Metadaten die Info zu finden war, dass Datensätze in der Spalte \"Q_TG\" mit den Werten 1 oder 9 ungültige Daten enthalten, entfernen wir diese Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddd2065a-e77a-4b8d-926c-e145495b8d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| SOUID|count|\n",
      "+------+-----+\n",
      "|234722|30621|\n",
      "|234943|29673|\n",
      "|235008|20511|\n",
      "|236256|17655|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF = sparkDF.filter(col(\"Q_TG\") == '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba5c6c-33dc-4eb6-9011-7a74985d90b7",
   "metadata": {},
   "source": [
    "Man sieht nun, dass einige Datensätze entfernt wurden, vor allem bei der Station 236256 Güssing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218cf9ef-3a9f-46c4-841c-d9f8a062bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkDF.groupby('SOUID').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a894ea9-73cb-4c0c-a674-9b36d990643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STAID: long (nullable = true)\n",
      " |-- SOUID: long (nullable = true)\n",
      " |-- DATE: long (nullable = true)\n",
      " |-- TG: long (nullable = true)\n",
      " |-- Q_TG: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac596a13-1d9a-4384-b4a2-a4855a787e85",
   "metadata": {},
   "source": [
    "Nun werden noch die unnötigen Spalten entfernt und die Temperatur auf Grad skaliert: es stehen nun nur noch die interessierenden Werte Station, Datum und mittlere Temperatur zur Verfügung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73c3214f-4ad8-43e8-abca-a87e21895e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SOUID: long (nullable = true)\n",
      " |-- DATE: long (nullable = true)\n",
      " |-- TG: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF = sparkDF.drop(\"STAID\", \"Q_TG\")\n",
    "sparkDF = sparkDF.withColumn(\"TG\", round(sparkDF.TG / 10, 2))\n",
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bec9d-413b-4264-8cf1-9b4729795157",
   "metadata": {},
   "source": [
    "Erneut speichern wir das File für die Temperaturdatenn lokal im hdf5-Format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd2301ab-274b-496f-a6ea-6c976832b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = sparkDF.toPandas()\n",
    "tg.to_hdf('../data/ecad/TG.h5', key='all', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
